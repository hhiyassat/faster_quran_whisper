# faster_quran_whisper

Faster-Whisper speech-to-text pipeline with VAD for **Quran audio transcription** in Arabic.

## ğŸš€ Quick Start

### 1. Create Virtual Environment
```bash
cd faster-whisper
python3 -m venv venv
source venv/bin/activate
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

### 3. Run
```bash
python main.py
```

To use custom audio file:
```bash
python main.py /path/to/your/audio.mp3
```

## ğŸ“¥ Input Example

**Input:** Quran audio file (MP3, WAV, M4A, AAC, FLAC)

Example audio file: `sample/quran_test_audio.mp3`
- Format: MP3
- Duration: ~20 minutes (Surah Al-Kahf)
- Sample Rate: 16kHz (auto-resampled if needed)

## ğŸ“¤ Output Example

**Output:** Arabic text transcription

Example output:
```
Ø§Ù„Ø­Ù…Ø¯ Ù„Ù„Ù‡ Ø§Ù„Ø°ÙŠ Ø£Ù†Ø²Ù„ Ø¹Ù„Ù‰ Ø¹Ø¨Ø¯Ù‡ Ø§Ù„ÙƒØªØ§Ø¨ ÙˆÙ„Ù… ÙŠØ¬Ø¹Ù„ Ù„Ù‡ Ø¹ÙˆØ¬Ø§
Ù‚ÙŠÙ…Ø§ Ù„ÙŠÙ†Ø°Ø± Ø¨Ø£Ø³Ø§ Ø´Ø¯ÙŠØ¯Ø§ Ù…Ù† Ù„Ø¯Ù†Ù‡ ÙˆÙŠØ¨Ø´Ø± Ø§Ù„Ù…Ø¤Ù…Ù†ÙŠÙ† Ø§Ù„Ø°ÙŠÙ† ÙŠØ¹Ù…Ù„ÙˆÙ† Ø§Ù„ØµØ§Ù„Ø­Ø§Øª Ø£Ù† Ù„Ù‡Ù… Ø£Ø¬Ø±Ø§ Ø­Ø³Ù†Ø§
```

The script processes the audio, detects speech segments, transcribes each segment, and combines them into full text.

## ğŸ“ Folder Structure

```
faster-whisper/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ config.py              # Configuration
â”œâ”€â”€ main.py                # Entry point
â”œâ”€â”€ models/                # All models
â”‚   â”œâ”€â”€ whisper/          # Faster-Whisper model
â”‚   â”œâ”€â”€ vad/              # VAD model and utilities
â”‚   â””â”€â”€ loader.py         # Model loading
â”œâ”€â”€ audio/                # Audio processing
â”‚   â””â”€â”€ loader.py
â”œâ”€â”€ vad/                  # VAD processing module
â”‚   â””â”€â”€ processor.py
â”œâ”€â”€ transcriber/          # Transcription module
â”‚   â””â”€â”€ processor.py
â”œâ”€â”€ sample/               # Sample audio files
â”‚   â””â”€â”€ quran_test_audio.mp3
â””â”€â”€ venv/                 # Virtual environment
```

## ğŸ”„ How It Works

1. **VAD Processing**: Detects speech segments in audio
2. **Transcription**: Each segment transcribed using Faster-Whisper
3. **Combination**: All transcriptions merged into full text

## âš™ï¸ Configuration

Edit `config.py` to customize:
- Audio file path
- Model settings (device, threads, quantization)
- VAD parameters (threshold, duration)
- Transcription settings

## ğŸ“¦ Requirements

- Python 3.8+
- See `requirements.txt` for dependencies

## ğŸ”§ Troubleshooting

**Model not found?**
```bash
ls -la models/whisper/
ls -la models/vad/silero_vad.onnx
```

**Audio format error?**
Install codecs: `sudo apt-get install ffmpeg libavcodec-extra`

## ğŸ“„ License

- Faster-Whisper: MIT
- Silero VAD: Apache 2.0
- CTranslate2: MIT
