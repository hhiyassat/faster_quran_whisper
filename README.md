# faster_quran_whisper

Faster-Whisper speech-to-text pipeline with VAD for **Quran audio transcription** in Arabic.

## ğŸš€ Quick Start

### 1. Create Virtual Environment
```bash
cd faster-whisper
python3 -m venv venv
source venv/bin/activate
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

### 3. Run
```bash
python main.py
```

To use custom audio file:
```bash
python main.py /path/to/your/audio.mp3
```

## ğŸ“¥ Input Example

**Input:** Quran audio file (MP3, WAV, M4A, AAC, FLAC)

Example audio file: `sample/quran_test_audio.mp3`
- Format: MP3
- Duration: ~20 minutes (Surah Al-Kahf)
- Sample Rate: 16kHz (auto-resampled if needed)

## ğŸ“¤ Output Example

**Output:** Structured transcription with timestamps for each spoken segment

Example output format:
```
============================================================
ğŸ¤ TRANSCRIBING 106 SEGMENTS
============================================================

[Segment 1/106]
   Duration: 12.85s
   Time range: 1.25s - 14.10s
   âœ… Transcription: Ø¡ÙÙ„Ø­ÙÙ…Ø¯ÙÙˆÙˆÙ„ÙÙ„Ù„ÙØ§Ø§Ù‡ÙÙ„Ù„Ù Ø°ÙÙŠÙŠÙŠÙŠÙŠ Ø¡ÙÚ»Ø²ÙÙ„Ù Ø¹ÙÙ„ÙØ§Ø§ Ø¹ÙÙ¾Ø¯ÙÙ‡Ù Ù„ÙƒÙØªÙØ§Ø§Ø¨Ù ÙˆÙÙ„ÙÙ… ÙŠÙÚ†Ø¹ÙÙ„Ù„ÙÙ‡ÙÙˆÙˆØ¹Ù ÙˆÙØ¬ÙØ§Ø§

[Segment 2/106]
   Duration: 19.64s
   Time range: 15.20s - 34.84s
   âœ… Transcription: Ú¨ÙÙŠÙŠÙÙ…ÙÙ„Ù„Ù ÙŠÙÚ»Ø°ÙÚ—ÙØ¨ÙØ¡Ù Ø³ÙÚ» Ø´ÙØ¯ÙÙŠÙŠØ¯ÙÙ…Ù…ÙÙ„Ù„ÙØ¯ÙÙ†Ù‡Ù ÙˆÙ ÙŠÙØ¨ÙØ´Ø´ÙÚ—ÙÙ„Ù…ÙØ¡ÙÙ…ÙÙ†ÙÙŠÙŠÙ†ÙÙ„Ù„ÙØ°ÙÙŠÙŠÙ†Ù ÙŠÙØ¹Ù…ÙÙ„ÙÙˆÙˆÙ†Ù ÚØµÙÙ„ÙØ­ÙØ§Ø§ØªÙ

============================================================
ğŸ“Š SUMMARY
============================================================
Total segments: 106
Successfully transcribed: 106
Failed: 0

============================================================
ğŸ“„ FULL TRANSCRIPTION:
============================================================
Ø¡ÙÙ„Ø­ÙÙ…Ø¯ÙÙˆÙˆÙ„ÙÙ„Ù„ÙØ§Ø§Ù‡ÙÙ„Ù„Ù Ø°ÙÙŠÙŠÙŠÙŠÙŠ Ø¡ÙÚ»Ø²ÙÙ„Ù Ø¹ÙÙ„ÙØ§Ø§ Ø¹ÙÙ¾Ø¯ÙÙ‡Ù Ù„ÙƒÙØªÙØ§Ø§Ø¨Ù...
   Total length: 6995 characters
   Total tokens (approx): ~608 words
```

The output includes:
- **Per-segment transcription** with timestamps (start/end time, duration)
- **Full combined transcription** with all segments merged
- **Summary statistics** (total segments, success rate)

## ğŸ“ Folder Structure

```
faster-whisper/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ config.py              # Configuration
â”œâ”€â”€ main.py                # Entry point
â”œâ”€â”€ models/                # All models
â”‚   â”œâ”€â”€ whisper/          # Faster-Whisper model
â”‚   â”œâ”€â”€ vad/              # VAD model and utilities
â”‚   â””â”€â”€ loader.py         # Model loading
â”œâ”€â”€ audio/                # Audio processing
â”‚   â””â”€â”€ loader.py
â”œâ”€â”€ vad/                  # VAD processing module
â”‚   â””â”€â”€ processor.py
â”œâ”€â”€ transcriber/          # Transcription module
â”‚   â””â”€â”€ processor.py
â”œâ”€â”€ sample/               # Sample audio files
â”‚   â””â”€â”€ quran_test_audio.mp3
â””â”€â”€ venv/                 # Virtual environment
```

## ğŸ”„ How It Works

1. **VAD Processing**: Detects speech segments in audio
2. **Transcription**: Each segment transcribed using Faster-Whisper
3. **Combination**: All transcriptions merged into full text with timestamps

## âš¡ Performance

- **CPU optimized**: Uses int8 quantization for fast CPU inference
- **Real-time factor**: ~14.6x faster than real-time (20 min audio in ~82 seconds)
- **Multi-threaded**: Configurable CPU threads (default: 4)
- **Efficient**: CTranslate2 backend for optimized inference

## âš™ï¸ Configuration

Edit `config.py` to customize:
- Audio file path
- Model settings (device, threads, quantization)
- VAD parameters (threshold, duration)
- Transcription settings

## ğŸ“¦ Requirements

- Python 3.8+
- See `requirements.txt` for dependencies

## ğŸ”§ Troubleshooting

**Model not found?**
```bash
ls -la models/whisper/
ls -la models/vad/silero_vad.onnx
```

**Audio format error?**
Install codecs: `sudo apt-get install ffmpeg libavcodec-extra`

## ğŸ“„ License

- Faster-Whisper: MIT
- Silero VAD: Apache 2.0
- CTranslate2: MIT
