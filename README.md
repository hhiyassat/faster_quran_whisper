# faster_quran_whisper

Faster-Whisper speech-to-text pipeline with VAD for Arabic transcription.

## ğŸš€ Quick Start

### 1. Create Virtual Environment
```bash
cd faster-whisper
python3 -m venv venv
source venv/bin/activate
```

### 2. Install Dependencies
```bash
pip install -r requirements.txt
```

### 3. Run
```bash
python main.py
```

To use custom audio file:
```bash
python main.py /path/to/your/audio.mp3
```

## ğŸ“ Folder Structure

```
faster-whisper/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ config.py              # Configuration
â”œâ”€â”€ main.py                # Entry point
â”œâ”€â”€ models/                # All models
â”‚   â”œâ”€â”€ whisper/          # Faster-Whisper model
â”‚   â”œâ”€â”€ vad/              # VAD model and utilities
â”‚   â””â”€â”€ loader.py         # Model loading
â”œâ”€â”€ audio/                # Audio processing
â”‚   â””â”€â”€ loader.py
â”œâ”€â”€ vad/                  # VAD processing module
â”‚   â””â”€â”€ processor.py
â”œâ”€â”€ transcriber/          # Transcription module
â”‚   â””â”€â”€ processor.py
â”œâ”€â”€ sample/               # Sample audio files
â”‚   â””â”€â”€ quran_test_audio.mp3
â””â”€â”€ venv/                 # Virtual environment
```

## ğŸ”„ How It Works

1. **VAD Processing**: Detects speech segments in audio
2. **Transcription**: Each segment transcribed using Faster-Whisper
3. **Combination**: All transcriptions merged into full text

## âš™ï¸ Configuration

Edit `config.py` to customize:
- Audio file path
- Model settings (device, threads, quantization)
- VAD parameters (threshold, duration)
- Transcription settings

## ğŸ“¦ Requirements

- Python 3.8+
- See `requirements.txt` for dependencies

## ğŸ”§ Troubleshooting

**Model not found?**
```bash
ls -la models/whisper/
ls -la models/vad/silero_vad.onnx
```

**Audio format error?**
Install codecs: `sudo apt-get install ffmpeg libavcodec-extra`

## ğŸ“„ License

- Faster-Whisper: MIT
- Silero VAD: Apache 2.0
- CTranslate2: MIT
